# YOLO-BASED-CLASSROOM-ANALYTICS (YOLO + Jetson + OpenCV)

A real-time, privacy-friendly classroom monitoring solution built using **YOLO object detection**, **OpenCV**, and **NVIDIA Jetson** hardware.  
The system detects students, estimates engagement, and logs analytics â€” all without storing identities or video.

---

## âœ¨ Features

- ğŸ¯ Real-time student detection using YOLO  
- ğŸ‘ï¸ Engagement estimation using spatial zones (middle 1/3 Ã— upper 2/3)  
- ğŸ”’ Privacy-preserving (no facial recognition, no image storage)  
- ğŸ“ˆ Automatic CSV logging for analytics  
- âš¡ Optimized for NVIDIA Jetson devices  
- ğŸ¥ Live annotated video feed  
- ğŸ“· Works with a single USB camera  

---

## ğŸ§° System Requirements

- NVIDIA Jetson (Nano, Xavier, Orin)  
- Ubuntu + JetPack  
- Python 3.10+  
- USB webcam (e.g., Sandberg)  
- YOLO11 model weights (`yolo11n.pt`)  

---

## ğŸš€ Installation

### 1ï¸âƒ£ Create Project Folder
```bash
mkdir ~/classroom_yolo
cd ~/classroom_yolo
```

### 2ï¸âƒ£ Create Virtual Environment
```bash
sudo apt install -y python3.10-venv python3-pip-whl python3-setuptools-whl
python3 -m venv ~/yolo_env
source ~/yolo_env/bin/activate
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install --upgrade pip setuptools wheel
pip install "numpy<2.0" opencv-python ultralytics
pip install https://github.com/sudoRicheek/jetson-wheels/releases/download/jp6-cu126/torch-2.8.0-cp310-cp310-linux_aarch64.whl
```

### 4ï¸âƒ£ Download YOLO Model
```bash
yolo download model=yolo11n.pt
```
Move yolo11n.pt to ~/classroom_yolo.

## â–¶ï¸ Running the Program
### Activate environment:
```bash
source ~/yolo_env/bin/activate
cd ~/classroom_yolo
```
### Run:
```bash
python3 classroom_monitor.py
```
### Exit:
Press q in the video window.

## ğŸ§  How It Works

### 1. Camera Capture
The system tries:
  - A GStreamer pipeline (Jetson optimized), then
  - Fallback to cv2.VideoCapture(0).

### 2. YOLO Detection
  - Detects only the person class
  - Counts the number of detected students
    
### 3. Engagement Estimation
A student is considered engaged if the center of their bounding box is in:
  - The middle third horizontally, and
  - The upper two-thirds vertically
This is a simple, privacy-safe heuristic.

### 4. Smoothing
A deque(maxlen=30) keeps recent engagement values and averages them,
creating a stable engagement metric.

### 5. Logging
Every LOG_INTERVAL seconds (default 10 sec), the system writes:
```bash
timestamp, num_students, engagement
```
to classroom_log.csv.
### 6. Display
Shows:
  - Bounding boxes
  - Student count
  - Engagement %
  - Engagement zone rectangle

---

## ğŸ”® Future Enhancements

  - ğŸ¤– Head-pose estimation for improved engagement accuracy
  
  - ğŸ§ YOLO Pose model for body posture and keypoints
  
  - ğŸ§ª Additional behaviors (phone use, hand-raising, etc.)
  
 -  ğŸ–¥ï¸ Web dashboard (Flask + Chart.js)
  
  - ğŸ¥ Multi-camera support
  
  - ğŸª‘ Seat-map occupancy detection
  
  - âš™ï¸ TensorRT optimization

---

## ğŸ” Privacy Notice

  - This system:
  
  - Does not store images or videos
  
  - Does not perform facial recognition
  
  - Logs only anonymous aggregate values
  
  - Processes all data locally on the Jetson device
